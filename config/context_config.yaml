# config/context_config.yaml
# Конфигурация системы управления контекстом с многоуровневой суммаризацией

context:
  enabled: true
  
  structure:
    raw_tail:  # Сырой хвост (последние n символов)
      char_limit: 3000  # Лимит символов для хранения последних сообщений
      
    l1_chunks:  # Чанки первого уровня
      target_char_limit: 3000  # Максимальный размер чанка
      allow_single_interaction_overflow: true  # Разрешить переполнение одним взаимодействием
      
    thresholds:  # Пороги суммаризации
      l2_trigger_count: 4  # Количество чанков L1 для запуска L2 суммаризации
      l2_preserve_ratio: 0.5  # Доля старейших чанков для L2 суммаризации
      
    cumulative:  # Кумулятивная строка результатов L2 суммаризаций
      max_blocks: 20  # Максимальное количество блоков L2
      # cleanup_old_blocks: false  # Зарезервировано для будущей реализации

  models:  # Конфигурация моделей суммаризации
    l1_summarizer:
      name: "Qwen/Qwen3-1.7B-MLX-4bit"
      local_path: "./llm_cache/models--Qwen--Qwen3-1.7B-MLX-4bit/snapshots/21457c6f51ed54a7c16e988c0844db973815c137"
      
    l2_summarizer:
      name: "Qwen/Qwen3-4B-MLX-4bit"  
      local_path: "./llm_cache/models--Qwen--Qwen3-4B-MLX-4bit/snapshots/52a5ab34fa604bc8af6d3ce0cac0cab10b7eb495"
    
    loading:  # Параметры загрузки моделей
      preload: true  # Предзагружать при старте приложения
      warmup: true   # Прогревать после загрузки (требует preload: true)
      warmup_text: "Для прогрева моделей суммаризаторов необходимо ввести тестовое сообщение. Оно должно быть не очень длинное, а результат нас не интересует вовсе - вывод модели будет заглушен. Однако, текст должен быть осмысленным, чтобы модель смогла его корректно воспринять. На вход обеих моделей будет подан одинаковый текст."

    generation_params:  # Параметры генерации для суммаризаций
      l1:
        max_tokens: 800           # Максимальное количество токенов для L1
        temperature: 0.4          # Детерминированные конспекты
        top_p: 0.9
        top_k: 40
        repetition_penalty: 1.1
        enable_thinking: false    # Всегда отключено для суммаризации
        
      l2:
        max_tokens: 300           # Максимальное количество токенов для L2
        temperature: 0.4          # Творческое обобщение
        top_p: 0.9
        top_k: 40
        repetition_penalty: 1.1
        enable_thinking: false    # Всегда отключено для суммаризации

  performance:
    background_summary: true      # Фоновая суммаризация
    max_background_tasks: 2       # Максимальное количество фоновых задач
    summary_delay_ms: 1000        # Задержка перед началом суммаризации (мс)
    
    # Размеры батчей (зарезервировано для будущей реализации)
    # batch_size_l1: 1
    # batch_size_l2: 1

  persistence:
    save_with_dialog: true        # Сохранять контекст вместе с диалогом
    auto_save_interval: 60        # Автосохранение каждые N секунд
    # compression: "gzip"         # Зарезервировано для будущей реализации

  monitoring:
    enable_stats: true            # Сбор статистики
    log_summary_events: true      # Логирование событий суммаризации
    log_compression_ratios: true  # Логирование коэффициентов сжатия