# /run.py (–æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏)

def print_memory_stats(prefix: str = ""):
    """–í—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–∞–º—è—Ç–∏ –¥–ª—è MLX"""
    try:
        import psutil
        
        process = psutil.Process()
        memory_info = process.memory_info()
        
        ram_used = memory_info.rss / 1024**3
        ram_percent = process.memory_percent()
        
        print(f"{prefix}üíæ RAM: {ram_used:.2f} GB ({ram_percent:.1f}%)")
        
        # –î–ª—è MLX –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ VRAM —á–µ—Ä–µ–∑ Activity Monitor
        print(f"{prefix}üéÆ MLX: Apple Silicon (–æ–±—â–∞—è –ø–∞–º—è—Ç—å)")
        
    except Exception as e:
        print(f"{prefix}‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–∞–º—è—Ç–∏: {e}")

def initialize_model():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ —á–µ—Ä–µ–∑ MLX"""
    print("\n" + "-" * 50)
    print("üì¶ –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ú–û–î–ï–õ–ò (MLX)")
    print("-" * 50)
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Å–µ—Ä–≤–∏—Å –º–æ–¥–µ–ª–∏
        model_service = container.get_model_service()
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–∏–º–µ–Ω–µ–Ω–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫
        config = container.get_config()
        user_settings = container.get("config_service").get_user_settings()
        
        if user_settings:
            print(f"üìù –ü—Ä–∏–º–µ–Ω–µ–Ω—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:")
            if "generation" in user_settings:
                gen = user_settings["generation"]
                if "max_tokens" in gen:
                    print(f"   –¢–æ–∫–µ–Ω—ã: {gen['max_tokens']}")
                if "temperature" in gen:
                    print(f"   –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {gen['temperature']}")
                if "enable_thinking" in gen:
                    print(f"   Thinking: {gen['enable_thinking']}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ MLX
        start_time = time.time()
        model, tokenizer, lock = model_service.initialize()
        load_time = time.time() - start_time
        
        if model is not None:
            print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —á–µ—Ä–µ–∑ MLX –∑–∞ {load_time:.2f} —Å–µ–∫—É–Ω–¥")
            
            # MLX –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç GPU/Neural Engine
            print("‚ö° –ú–æ–¥–µ–ª—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è Apple Silicon")
            
            return True
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ MLX")
            return False
            
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ MLX: {e}")
        import traceback
        traceback.print_exc()
        return False