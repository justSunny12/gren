# services/context/summarizers.py
"""
–°–µ—Ä–≤–∏—Å—ã —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –¥–ª—è –º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –û–î–ù–£ –º–æ–¥–µ–ª—å MLX –¥–ª—è –≤—Å–µ—Ö —É—Ä–æ–≤–Ω–µ–π —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
"""
import asyncio
import threading
import time
from typing import Dict, Any, Optional
from dataclasses import dataclass
from datetime import datetime
import re
import os

import mlx.core as mx
from mlx_lm import load, generate
from mlx_lm.sample_utils import make_sampler, make_logits_processors

from container import container


@dataclass
class SummaryResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏"""
    summary: str
    original_length: int
    summary_length: int
    compression_ratio: float
    processing_time: float
    success: bool
    error: Optional[str] = None


class BaseSummarizer:
    """
    –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ç–æ—Ä–æ–≤.
    –ú–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –∫–∞–∫ —Å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é, —Ç–∞–∫ –∏ —Å –æ–±—â–µ–π.
    """
    
    def __init__(
        self,
        model_config: Dict[str, Any],
        config: Dict[str, Any],
        model: Optional[Any] = None,
        tokenizer: Optional[Any] = None,
        model_lock: Optional[threading.RLock] = None
    ):
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–Ω—É–∂–Ω—ã –¥–ª—è –ø—Ä–æ–º–ø—Ç–æ–≤ –∏ fallback-–∑–∞–≥—Ä—É–∑–∫–∏)
        self.model_name = model_config.get("name", "unknown")
        self.local_path = model_config.get("local_path")
        self.config = config
        
        # --- –†–∞–∑–¥–µ–ª—è–µ–º –¥–≤–∞ —Ä–µ–∂–∏–º–∞ ---
        if model is not None and tokenizer is not None:
            # –†–ï–ñ–ò–ú 1: –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–æ—Ç–æ–≤—É—é –º–æ–¥–µ–ª—å (shared)
            self._model = model
            self._tokenizer = tokenizer
            self._model_lock = model_lock if model_lock else threading.RLock()
            self._owns_model = False          # –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞—à–∞, –≤—ã–≥—Ä—É–∂–∞—Ç—å –Ω–µ–ª—å–∑—è
            self._is_loading = False
            self._load_error = None
        else:
            # –†–ï–ñ–ò–ú 2: –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–≤–æ—é –º–æ–¥–µ–ª—å (legacy, –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
            self._model = None
            self._tokenizer = None
            self._model_lock = threading.RLock()
            self._owns_model = True
            self._is_loading = False
            self._load_error = None
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–º–æ–≥—É—Ç –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è—Ç—å—Å—è –≤ summarize)
        summarization_params = config.get("generation_params", {})
        model_type = "l1" if "L1" in self.__class__.__name__ else "l2"
        params = summarization_params.get(model_type, {})
        
        self.max_tokens = params.get("max_tokens", 200)
        self.temperature = params.get("temperature", 0.3)
        self.top_p = params.get("top_p", 0.9)
        self.top_k = params.get("top_k", 40)
        self.repetition_penalty = params.get("repetition_penalty", 1.1)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self._total_requests = 0
        self._successful_requests = 0
        self._total_processing_time = 0.0
        self._last_used: Optional[float] = None
    
    @property
    def is_loaded(self) -> bool:
        return self._model is not None and self._tokenizer is not None
    
    @property
    def is_loading(self) -> bool:
        return self._is_loading
    
    @property
    def stats(self) -> Dict[str, Any]:
        last_used_iso = None
        if self._last_used:
            try:
                last_used_iso = datetime.fromtimestamp(self._last_used).isoformat()
            except (ValueError, OSError):
                last_used_iso = str(self._last_used)
        return {
            'model_name': self.model_name,
            'is_loaded': self.is_loaded,
            'is_loading': self.is_loading,
            'load_error': self._load_error,
            'owns_model': self._owns_model,
            'total_requests': self._total_requests,
            'successful_requests': self._successful_requests,
            'failed_requests': self._total_requests - self._successful_requests,
            'success_rate': self._successful_requests / max(self._total_requests, 1),
            'avg_processing_time': self._total_processing_time / max(self._successful_requests, 1),
            'last_used': last_used_iso,
            'generation_params': {
                'max_tokens': self.max_tokens,
                'temperature': self.temperature,
                'top_p': self.top_p,
                'top_k': self.top_k,
                'repetition_penalty': self.repetition_penalty,
                'enable_thinking': False
            }
        }
    
    async def load_model(self) -> bool:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ –±—ã–ª–∞ –ø–µ—Ä–µ–¥–∞–Ω–∞ –∏–∑–≤–Ω–µ."""
        if not self._owns_model:
            # –£–∂–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –≥–æ—Ç–æ–≤—É—é –º–æ–¥–µ–ª—å, –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º
            return self.is_loaded
        
        with self._model_lock:
            if self.is_loaded:
                return True
            if self._is_loading:
                while self._is_loading:
                    await asyncio.sleep(0.1)
                return self.is_loaded
            
            self._is_loading = True
            self._load_error = None
            try:
                if not self.local_path:
                    self._load_error = f"–õ–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å –Ω–µ —É–∫–∞–∑–∞–Ω –¥–ª—è –º–æ–¥–µ–ª–∏ {self.model_name}"
                    print(f"‚ùå {self._load_error}")
                    return False
                if not os.path.exists(self.local_path):
                    self._load_error = f"–õ–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {self.local_path}"
                    print(f"‚ùå {self._load_error}")
                    return False
                
                start_time = time.time()
                self._model, self._tokenizer = load(self.local_path)
                
                if self._tokenizer.pad_token is None:
                    self._tokenizer.pad_token = self._tokenizer.eos_token
                self._tokenizer.padding_side = "left"
                
                load_time = time.time() - start_time
                print(f"   ‚úÖ –ú–æ–¥–µ–ª—å {self.model_name} –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∑–∞ {load_time:.2f} —Å–µ–∫")
                return True
                
            except Exception as e:
                error_msg = f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ {self.model_name} –∏–∑ {self.local_path}: {str(e)}"
                print(f"‚ùå {error_msg}")
                self._load_error = error_msg
                return False
            finally:
                self._is_loading = False
    
    async def ensure_loaded(self) -> bool:
        """–£–±–µ–∂–¥–∞–µ—Ç—Å—è, —á—Ç–æ –º–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ."""
        if not self._owns_model:
            # –í —Ä–µ–∂–∏–º–µ shared –º–æ–¥–µ–ª–∏ –≤—Å–µ–≥–¥–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≥–æ—Ç–æ–≤—ã (–∑–∞–≥—Ä—É–∂–µ–Ω—ã —Ñ–∞–±—Ä–∏–∫–æ–π)
            if not self.is_loaded:
                raise RuntimeError(f"Shared model {self.model_name} is not loaded in factory")
            return True
        
        # –°–æ–±—Å—Ç–≤–µ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞
        if not self.is_loaded and not self.is_loading:
            return await self.load_model()
        elif self.is_loading:
            while self._is_loading:
                await asyncio.sleep(0.1)
            return self.is_loaded
        return True
    
    async def summarize(
        self,
        text: str,
        system_prompt: Optional[str] = None,
        user_prompt: Optional[str] = None,
        **kwargs
    ) -> SummaryResult:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Å —Ä–µ–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª—å—é."""
        start_time = time.time()
        self._total_requests += 1
        
        try:
            if not await self.ensure_loaded():
                return SummaryResult(
                    summary="",
                    original_length=len(text),
                    summary_length=0,
                    compression_ratio=1.0,
                    processing_time=time.time() - start_time,
                    success=False,
                    error=f"–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {self._load_error}"
                )
            
            max_tokens = kwargs.get("max_tokens", self.max_tokens)
            temperature = kwargs.get("temperature", self.temperature)
            top_p = kwargs.get("top_p", self.top_p)
            top_k = kwargs.get("top_k", self.top_k)
            repetition_penalty = kwargs.get("repetition_penalty", self.repetition_penalty)
            enable_thinking = False
            
            system = system_prompt if system_prompt is not None else self._get_system_prompt(**kwargs)
            user = user_prompt if user_prompt is not None else self._get_user_prompt(text, **kwargs)
            
            messages = [
                {"role": "system", "content": system},
                {"role": "user", "content": user}
            ]
            
            try:
                prompt = self._tokenizer.apply_chat_template(
                    messages,
                    tokenize=False,
                    add_generation_prompt=True,
                    enable_thinking=enable_thinking
                )
            except Exception as e:
                prompt = f"<|im_start|>system\n{system}<|im_end|>\n"
                prompt += f"<|im_start|>user\n{user}<|im_end|>\n"
                prompt += f"<|im_start|>assistant\n"
            
            sampler = make_sampler(temp=temperature, top_p=top_p, top_k=top_k)
            logits_processors = make_logits_processors(repetition_penalty=repetition_penalty)
            
            with self._model_lock:
                response = generate(
                    model=self._model,
                    tokenizer=self._tokenizer,
                    prompt=prompt,
                    sampler=sampler,
                    logits_processors=logits_processors,
                    max_tokens=max_tokens,
                    verbose=False
                )
            
            summary_text = self._clean_response(response, prompt)
            processing_time = time.time() - start_time
            compression_ratio = len(text) / max(len(summary_text), 1)
            
            self._successful_requests += 1
            self._total_processing_time += processing_time
            self._last_used = time.time()
            
            return SummaryResult(
                summary=summary_text,
                original_length=len(text),
                summary_length=len(summary_text),
                compression_ratio=compression_ratio,
                processing_time=processing_time,
                success=True
            )
            
        except Exception as e:
            error_msg = f"–û—à–∏–±–∫–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏: {str(e)}"
            print(f"‚ùå {error_msg}")
            return SummaryResult(
                summary="",
                original_length=len(text),
                summary_length=0,
                compression_ratio=1.0,
                processing_time=time.time() - start_time,
                success=False,
                error=error_msg
            )
    
    def _clean_response(self, response: str, prompt: str) -> str:
        """–û—á–∏—â–∞–µ—Ç –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ –æ—Ç –ø—Ä–æ–º–ø—Ç–∞ –∏ –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤."""
        if response.startswith(prompt):
            response = response[len(prompt):]
        response = response.strip()
        response = response.strip('"\'`')
        response = re.sub(r'<think>.*?</think>', '', response, flags=re.DOTALL)
        response = response.replace('<think>', '').replace('</think>', '').strip()
        return response
    
    def unload_model(self):
        """–í—ã–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –æ–Ω–∞ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç —ç—Ç–æ–º—É —ç–∫–∑–µ–º–ø–ª—è—Ä—É."""
        with self._model_lock:
            if self._owns_model and self._model is not None:
                self._model = None
                self._tokenizer = None
                if hasattr(mx, 'clear_cache'):
                    mx.clear_cache()
                print(f"‚úÖ –ú–æ–¥–µ–ª—å –≤—ã–≥—Ä—É–∂–µ–Ω–∞: {self.model_name}")
            elif not self._owns_model:
                # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –≤—ã–∑–æ–≤ –¥–ª—è shared-–º–æ–¥–µ–ª–∏
                pass
    
    # --- –ú–µ—Ç–æ–¥—ã, –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º—ã–µ –≤ –Ω–∞—Å–ª–µ–¥–Ω–∏–∫–∞—Ö ---
    def _get_system_prompt(self, **kwargs) -> str:
        raise NotImplementedError
    
    def _get_user_prompt(self, text: str, **kwargs) -> str:
        raise NotImplementedError


class L1Summarizer(BaseSummarizer):
    """–°—É–º–º–∞—Ä–∏–∑–∞—Ç–æ—Ä –ø–µ—Ä–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è (–ø–æ–¥—Ä–æ–±–Ω—ã–µ –∫–æ–Ω—Å–ø–µ–∫—Ç—ã)"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.max_input_length = self.config.get("l1_chunks", {}).get("max_char_limit", 2000)
    
    def _get_system_prompt(self, **kwargs) -> str:
        return """–¢—ã —Å–æ–∑–¥–∞—ë—à—å –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–Ω—Å–ø–µ–∫—Ç—ã –¥–∏–∞–ª–æ–≥–æ–≤ –¥–ª—è –∫—Ä–∞—Ç–∫–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø–∞–º—è—Ç–∏ —Å–∏—Å—Ç–µ–º—ã.
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–∞–∫—Å–∏–º—É–º –≤–∞–∂–Ω—ã—Ö –¥–µ—Ç–∞–ª–µ–π, —Ñ–∞–∫—Ç–æ–≤, —Ä–µ—à–µ–Ω–∏–π –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –∫–æ–Ω—Å–ø–µ–∫—Ç—É:
0. –ù–µ –ø–∏—à–∏ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∏ –Ω–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–π —Ç–µ–∫—Å—Ç
1. –°–æ—Ö—Ä–∞–Ω–∏ –≤—Å–µ –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã, –¥–∞–Ω–Ω—ã–µ, –∏–º–µ–Ω–∞, –¥–∞—Ç—ã, —á–∏—Å–ª–∞
2. –ü–µ—Ä–µ—á–∏—Å–ª–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è, –¥–µ–π—Å—Ç–≤–∏—è, –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
3. –ó–∞—Ñ–∏–∫—Å–∏—Ä—É–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ–±—Å—É–∂–¥–µ–Ω–∏—è –∏ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Å–≤—è–∑–∏
4. –û—Ç–º–µ—Ç—å –≤–∞–∂–Ω—ã–µ –≤—ã–≤–æ–¥—ã –∏ —Å–æ–≥–ª–∞—à–µ–Ω–∏—è
5. –°–æ—Ö—Ä–∞–Ω–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏, –∫–æ–º–∞–Ω–¥—ã, –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
6. –ë—É–¥—å –ø–æ–¥—Ä–æ–±–Ω—ã–º, –Ω–æ –∏–∑–±–µ–≥–∞–π –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π
7. –ö–æ–Ω—Å–ø–µ–∫—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∞ —è–∑—ã–∫–µ –∏—Å—Ö–æ–¥–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π

–§–æ—Ä–º–∞—Ç: —Å–ø–ª–æ—à–Ω–æ–π —Å–≤—è–∑–Ω—ã–π —Ç–µ–∫—Å—Ç, 5-7 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–µ—Ç–∞–ª–µ–π."""
    
    def _get_user_prompt(self, text: str, **kwargs) -> str:
        # –ü—Ä–æ—Å—Ç–æ–µ –æ–±—Ä–µ–∑–∞–Ω–∏–µ, –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
        if len(text) > self.max_input_length:
            text = text[:self.max_input_length] + "...[—Ç–µ–∫—Å—Ç –æ–±—Ä–µ–∑–∞–Ω]"
        return f"""–î–∏–∞–ª–æ–≥ –¥–ª—è –∫–æ–Ω—Å–ø–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:

{text}

–°–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–∏–π –∫–æ–Ω—Å–ø–µ–∫—Ç —ç—Ç–æ–≥–æ –æ–±—Å—É–∂–¥–µ–Ω–∏—è, —Å–ª–µ–¥—É—è —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º –≤—ã—à–µ:"""
    
    def _clean_response(self, response: str, prompt: str) -> str:
        cleaned = super()._clean_response(response, prompt)
        if cleaned and not cleaned.startswith("[L1 Summary]"):
            cleaned = f"[L1 Summary] {cleaned}"
        return cleaned


class L2Summarizer(BaseSummarizer):
    """–°—É–º–º–∞—Ä–∏–∑–∞—Ç–æ—Ä –≤—Ç–æ—Ä–æ–≥–æ —É—Ä–æ–≤–Ω—è (—Å–∂–∞—Ç—ã–µ –æ–±–æ–±—â–µ–Ω–∏—è)"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.max_input_length = self.config.get("l2_summary", {}).get("max_char_limit", 4000)
    
    def _get_system_prompt(self, **kwargs) -> str:
        return """–¢—ã ‚Äî –∞–Ω–∞–ª–∏—Ç–∏–∫ –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—Å—É–∂–¥–µ–Ω–∏–π. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —Å–æ–∑–¥–∞–≤–∞—Ç—å —Å–∂–∞—Ç—ã–µ —Å–≤–æ–¥–Ω—ã–µ –∑–∞–ø–∏—Å–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∫–æ–Ω—Å–ø–µ–∫—Ç–æ–≤.

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Å–≤–æ–¥–Ω–æ–π –∑–∞–ø–∏—Å–∏:
0. –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –∑–∞–≥–æ–ª–æ–≤–∫–∏, —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ Markdown
1. –°–æ—Ö—Ä–∞–Ω–∏ —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—é –æ–±—Å—É–∂–¥–∞–µ–º—ã—Ö —Ç–µ–º
2. –í—ã–¥–µ–ª–∏ –∫–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏ —Ä–∞–∑–≤–∏—Ç–∏—è –æ–±—Å—É–∂–¥–µ–Ω–∏—è
3. –û—Ç–º–µ—Ç—å –ø—Ä–∏–Ω—è—Ç—ã–µ —Ä–µ—à–µ–Ω–∏—è –∏ –∏—Ö —ç–≤–æ–ª—é—Ü–∏—é
4. –ü–æ–∫–∞–∂–∏ —Å–≤—è–∑—å –º–µ–∂–¥—É —Ä–∞–∑–Ω—ã–º–∏ —á–∞—Å—Ç—è–º–∏ –æ–±—Å—É–∂–¥–µ–Ω–∏—è
5. –ë—É–¥—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Å–∂–∞—Ç—ã–º, –Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏ —Å–º—ã—Å–ª–æ–≤—É—é —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å
6. –ü–æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–π –±–æ–ª–µ–µ –∫—Ä–∞—Ç–∫–∏–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏
7. –ö–æ–Ω—Å–ø–µ–∫—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∞ —è–∑—ã–∫–µ –∏—Å—Ö–æ–¥–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π

–§–æ—Ä–º–∞—Ç: –∫—Ä–∞—Ç–∫–∏–π —Å–≤—è–∑–Ω—ã–π —Ç–µ–∫—Å—Ç, 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."""
    
    def _get_user_prompt(self, text: str, **kwargs) -> str:
        if len(text) > self.max_input_length:
            text = text[:self.max_input_length] + "...[—Ç–µ–∫—Å—Ç –æ–±—Ä–µ–∑–∞–Ω]"
        return f"""–ö–æ–Ω—Å–ø–µ–∫—Ç—ã —á–∞—Å—Ç–µ–π –¥–∏–∞–ª–æ–≥–∞ (–≤ —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–º –ø–æ—Ä—è–¥–∫–µ):

{text}

–°–æ–∑–¥–∞–π —Å–∂–∞—Ç—É—é —Å–≤–æ–¥–Ω—É—é –∑–∞–ø–∏—Å—å, —Å–ª–µ–¥—É—è —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º –≤—ã—à–µ:"""
    
    def _clean_response(self, response: str, prompt: str) -> str:
        cleaned = super()._clean_response(response, prompt)
        if cleaned.startswith("[L1 Summary]"):
            cleaned = cleaned.replace("[L1 Summary]", "[L2 Summary]")
        elif cleaned and not cleaned.startswith("[L2 Summary]"):
            cleaned = f"[L2 Summary] {cleaned}"
        return cleaned.strip()


class SummarizerFactory:
    """–§–∞–±—Ä–∏–∫–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ç–æ—Ä–æ–≤ —Å –û–î–ù–û–ô –æ–±—â–µ–π –º–æ–¥–µ–ª—å—é."""
    
    _instances: Dict[str, BaseSummarizer] = {}
    _shared_model = None
    _shared_tokenizer = None
    _shared_lock = None
    _preloaded = False
    _lock = threading.RLock()
    
    @classmethod
    def get_all_summarizers(cls, config: Dict[str, Any]) -> Dict[str, BaseSummarizer]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä—ã L1 –∏ L2 —Å—É–º–º–∞—Ä–∏–∑–∞—Ç–æ—Ä–æ–≤, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏—Ö –û–î–ù–£ –º–æ–¥–µ–ª—å."""
        with cls._lock:
            # –ï—Å–ª–∏ —ç–∫–∑–µ–º–ø–ª—è—Ä—ã —É–∂–µ —Å–æ–∑–¥–∞–Ω—ã ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º
            if "l1" in cls._instances and "l2" in cls._instances:
                return cls._instances.copy()
            
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–¥–µ–ª–∏ (–µ–¥–∏–Ω–æ–π)
            model_config = config.get("model", {})
            if not model_config.get("local_path"):
                raise ValueError("–í context_config.yaml –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å–µ–∫—Ü–∏—è model.local_path")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –û–î–ò–ù –†–ê–ó
            if cls._shared_model is None or cls._shared_tokenizer is None:
                cls._load_shared_model(model_config)
            
            # –°–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä—ã —Å—É–º–º–∞—Ä–∏–∑–∞—Ç–æ—Ä–æ–≤ —Å –æ–±—â–µ–π –º–æ–¥–µ–ª—å—é –∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–æ–π
            cls._instances["l1"] = L1Summarizer(
                model_config, config,
                model=cls._shared_model,
                tokenizer=cls._shared_tokenizer,
                model_lock=cls._shared_lock
            )
            cls._instances["l2"] = L2Summarizer(
                model_config, config,
                model=cls._shared_model,
                tokenizer=cls._shared_tokenizer,
                model_lock=cls._shared_lock
            )
            
            return cls._instances.copy()
    
    @classmethod
    def _load_shared_model(cls, model_config: Dict[str, Any]):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—â—É—é –º–æ–¥–µ–ª—å –∏ —Å–æ–∑–¥–∞—ë—Ç –±–ª–æ–∫–∏—Ä–æ–≤–∫—É."""
        local_path = model_config.get("local_path")
        model_name = model_config.get("name", "Qwen/Qwen3-4B-MLX-4bit")
        
        if not local_path or not os.path.exists(local_path):
            raise FileNotFoundError(f"–ú–æ–¥–µ–ª—å —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–æ –ø—É—Ç–∏: {local_path}")
        
        print(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ {model_name}...")
        start = time.time()
        cls._shared_model, cls._shared_tokenizer = load(local_path)
        if cls._shared_tokenizer.pad_token is None:
            cls._shared_tokenizer.pad_token = cls._shared_tokenizer.eos_token
        cls._shared_tokenizer.padding_side = "left"
        cls._shared_lock = threading.RLock()
        print(f"   ‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∑–∞ {time.time() - start:.2f} —Å–µ–∫")
    
    @classmethod
    def preload_summarizers(cls, config: Dict[str, Any]) -> bool:
        """–ü—Ä–µ–¥–∑–∞–≥—Ä—É–∂–∞–µ—Ç –µ–¥–∏–Ω—É—é –º–æ–¥–µ–ª—å –∏ —Å–æ–∑–¥–∞—ë—Ç —Å—É–º–º–∞—Ä–∏–∑–∞—Ç–æ—Ä—ã."""
        with cls._lock:
            if cls._preloaded:
                return True
            
            loading_config = config.get("loading", {})
            if not loading_config.get("preload", True):
                print("‚ÑπÔ∏è –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ç–æ—Ä–æ–≤ –æ—Ç–∫–ª—é—á–µ–Ω–∞ –≤ –∫–æ–Ω—Ñ–∏–≥–µ")
                return False
            
            try:
                # –ü—Ä–æ—Å—Ç–æ –≤—ã–∑—ã–≤–∞–µ–º get_all_summarizers ‚Äî –æ–Ω–∞ –∑–∞–≥—Ä—É–∑–∏—Ç –º–æ–¥–µ–ª—å
                cls.get_all_summarizers(config)
                
                # --- –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ –∫–æ—Ä—É—Ç–∏–Ω—ã –ø—Ä–æ–≥—Ä–µ–≤–∞ ---
                if loading_config.get("warmup", True):
                    # –ü–æ–ª—É—á–∞–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞—ë–º event loop
                    try:
                        loop = asyncio.get_event_loop()
                    except RuntimeError:
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                    
                    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≥—Ä–µ–≤ –∏ –∂–¥—ë–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
                    warmup_text = loading_config.get("warmup_text", "–¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≥—Ä–µ–≤–∞.")
                    loop.run_until_complete(cls._warmup(warmup_text))
                
                cls._preloaded = True
                return True
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∏ —Å—É–º–º–∞—Ä–∏–∑–∞—Ç–æ—Ä–æ–≤: {e}")
                import traceback
                traceback.print_exc()
                return False
    
    @classmethod
    async def _warmup(cls, warmup_text: str):
        """–ü—Ä–æ–≥—Ä–µ–≤–∞–µ—Ç –º–æ–¥–µ–ª—å –∫–æ—Ä–æ—Ç–∫–∏–º –∑–∞–ø—Ä–æ—Å–æ–º."""
        # print("\nüî• –ü—Ä–æ–≥—Ä–µ–≤ —Å—É–º–º–∞—Ä–∏–∑–∞—Ç–æ—Ä–∞...")
        summarizers = cls.get_all_summarizers({})  # –∫–æ–Ω—Ñ–∏–≥ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω
        l1 = summarizers["l1"]
        try:
            await l1.summarize(warmup_text[:100], max_tokens=10, temperature=0.1)
            print("   ‚úÖ –ü—Ä–æ–≥—Ä–µ–≤ –º–æ–¥–µ–ª–∏ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –∑–∞–≤–µ—Ä—à—ë–Ω —É—Å–ø–µ—à–Ω–æ")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–æ–≥—Ä–µ–≤–∞: {e}")
    
    @classmethod
    def is_preloaded(cls) -> bool:
        return cls._preloaded
    
    @classmethod
    def unload_all(cls):
        """–í—ã–≥—Ä—É–∂–∞–µ—Ç –æ–±—â—É—é –º–æ–¥–µ–ª—å (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)."""
        with cls._lock:
            # –û—á–∏—â–∞–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ç–æ—Ä—ã
            cls._instances.clear()
            # –í—ã–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
            if cls._shared_model is not None:
                # MLX –Ω–µ –∏–º–µ–µ—Ç —è–≤–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞ –≤—ã–≥—Ä—É–∑–∫–∏, –ø—Ä–æ—Å—Ç–æ —É–¥–∞–ª—è–µ–º —Å—Å—ã–ª–∫–∏
                cls._shared_model = None
                cls._shared_tokenizer = None
                cls._shared_lock = None
                if hasattr(mx, 'clear_cache'):
                    mx.clear_cache()
                print("‚úÖ –ï–¥–∏–Ω–∞—è –º–æ–¥–µ–ª—å —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –≤—ã–≥—Ä—É–∂–µ–Ω–∞")
            cls._preloaded = False
    
    @classmethod
    def get_stats(cls) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Å—É–º–º–∞—Ä–∏–∑–∞—Ç–æ—Ä–∞–º –∏ –æ–±—â–µ–π –º–æ–¥–µ–ª–∏."""
        with cls._lock:
            stats = {
                'shared_model_loaded': cls._shared_model is not None,
                'preloaded': cls._preloaded,
                'summarizers': {}
            }
            for name, summarizer in cls._instances.items():
                try:
                    stats['summarizers'][name] = summarizer.stats
                except Exception as e:
                    stats['summarizers'][name] = {'error': str(e)}
            return stats